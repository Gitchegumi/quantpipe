# Data Model: Directional Backtesting System

**Feature**: 002-directional-backtesting
**Date**: 2025-10-29
**Purpose**: Define data structures, flows, and transformations

## Overview

This document describes the data entities, their relationships, and data flows through the directional backtesting system. All entities build upon existing models defined in `src/models/core.py`.

## Core Entities

### Existing Entities (Reference Only)

These entities are already defined in the codebase and will be reused without modification:

#### Candle

**Location**: `src/models/core.py`

**Purpose**: Represents a single OHLCV price candle

**Fields**:

- `timestamp_utc`: datetime - Candle timestamp in UTC
- `open`: float - Opening price
- `high`: float - Highest price
- `low`: float - Lowest price
- `close`: float - Closing price
- `volume`: int - Trading volume

**Validation Rules**:

- `high >= max(open, close)`
- `low <= min(open, close)`
- Timestamps must be in UTC

---

#### TradeSignal

**Location**: `src/models/core.py`

**Purpose**: Represents a trade entry signal generated by strategy

**Fields**:

- `id`: str - Deterministic hash (SHA-256 truncated, lowercase hex)
- `timestamp_utc`: datetime - Signal generation time
- `pair`: str - Currency pair (e.g., "EURUSD")
- `direction`: str - Trade direction ("LONG" or "SHORT")
- `entry_price`: float - Intended entry price
- `stop_price`: float - Initial stop-loss price
- `risk_per_trade_pct`: float - Risk percentage
- `calc_position_size`: float - Calculated position size
- `tags`: list[str] - Strategy-specific tags
- `version`: str - Strategy version

**Validation Rules**:

- `direction` in {"LONG", "SHORT"}
- `entry_price > 0`
- `stop_price > 0`
- For LONG: `stop_price < entry_price`
- For SHORT: `stop_price > entry_price`

---

#### TradeExecution

**Location**: `src/models/core.py`

**Purpose**: Represents completed trade execution result

**Fields**:

- `signal_id`: str - Reference to originating signal
- `entry_timestamp_utc`: datetime - Actual entry time
- `entry_fill_price`: float - Actual entry price (with slippage)
- `exit_timestamp_utc`: datetime - Actual exit time
- `exit_fill_price`: float - Actual exit price (with slippage)
- `exit_reason`: str - Exit reason ("TARGET", "STOP", "TIMEOUT")
- `pnl_r`: float - Profit/loss in R-multiples
- `duration_candles`: int - Trade duration in candles

**Validation Rules**:

- `exit_timestamp_utc > entry_timestamp_utc`
- `duration_candles >= 0`

---

#### BacktestRun

**Location**: `src/models/core.py`

**Purpose**: Metadata container for backtest execution

**Fields**:

- `run_id`: str - Unique run identifier (e.g., "long_20251029_143052")
- `parameters_hash`: str - Hash of strategy parameters
- `manifest_ref`: str - Data manifest reference
- `start_time`: datetime - Backtest start timestamp
- `end_time`: datetime - Backtest end timestamp
- `total_candles_processed`: int - Number of candles processed
- `reproducibility_hash`: str - Hash for determinism verification

**Validation Rules**:

- `end_time >= start_time`
- `total_candles_processed >= 0`

---

#### MetricsSummary

**Location**: `src/models/core.py`

**Purpose**: Aggregated performance metrics

**Fields**:

- `trade_count`: int - Total number of trades
- `win_count`: int - Number of winning trades
- `loss_count`: int - Number of losing trades
- `win_rate`: float - Percentage of winning trades
- `avg_win_r`: float - Average R-multiple for wins
- `avg_loss_r`: float - Average R-multiple for losses
- `avg_r`: float - Average R-multiple across all trades
- `expectancy`: float - Expected value per trade
- `sharpe_estimate`: float - Sharpe ratio estimate
- `profit_factor`: float - Gross profit / gross loss
- `max_drawdown_r`: float - Maximum drawdown in R-multiples
- `latency_p95_ms`: float - 95th percentile execution latency
- `latency_mean_ms`: float - Mean execution latency

**Validation Rules**:

- `trade_count = win_count + loss_count`
- `win_rate = win_count / trade_count` (if trade_count > 0)
- All R-multiples can be NaN if trade_count == 0

---

### New Entities

#### DirectionMode (Enum)

**Purpose**: Enumeration of supported backtest direction modes

**Values**:

- `LONG`: Long-only signal generation
- `SHORT`: Short-only signal generation
- `BOTH`: Both long and short signals

**Validation Rules**:

- Must be one of the three defined values

**Usage**:

```python
from enum import Enum

class DirectionMode(str, Enum):
    LONG = "LONG"
    SHORT = "SHORT"
    BOTH = "BOTH"
```

---

#### OutputFormat (Enum)

**Purpose**: Enumeration of supported output formats

**Values**:

- `TEXT`: Human-readable text output
- `JSON`: Machine-readable JSON output

**Validation Rules**:

- Must be one of the two defined values

**Usage**:

```python
from enum import Enum

class OutputFormat(str, Enum):
    TEXT = "text"
    JSON = "json"
```

---

#### ConflictEvent

**Purpose**: Records signal conflict in BOTH mode

**Fields**:

- `timestamp_utc`: datetime - Timestamp of conflicting signals
- `pair`: str - Currency pair
- `resolution`: str - Resolution action taken ("REJECTED_BOTH")

**Validation Rules**:

- `resolution` must be "REJECTED_BOTH" (per clarification Q1)

**Usage**:

```python
from pydantic import BaseModel
from datetime import datetime

class ConflictEvent(BaseModel):
    timestamp_utc: datetime
    pair: str
    resolution: str = "REJECTED_BOTH"
```

---

#### DirectionalMetrics

**Purpose**: Container for separate long/short/combined metrics in BOTH mode

**Fields**:

- `long_only`: MetricsSummary | None - Metrics for long trades only
- `short_only`: MetricsSummary | None - Metrics for short trades only
- `combined`: MetricsSummary - Metrics for all trades aggregated

**Validation Rules**:

- In BOTH mode: all three fields populated
- In LONG mode: only `long_only` and `combined` populated (equal values)
- In SHORT mode: only `short_only` and `combined` populated (equal values)

**Usage**:

```python
from pydantic import BaseModel
from typing import Optional

class DirectionalMetrics(BaseModel):
    long_only: Optional[MetricsSummary] = None
    short_only: Optional[MetricsSummary] = None
    combined: MetricsSummary
```

---

#### BacktestResult

**Purpose**: Complete backtest result container

**Fields**:

- `run_metadata`: BacktestRun - Execution metadata
- `metrics`: DirectionalMetrics - Performance metrics
- `signals`: list[TradeSignal] - Generated signals (optional, for dry-run)
- `executions`: list[TradeExecution] - Completed executions (optional)
- `conflicts`: list[ConflictEvent] - Conflict events (BOTH mode only)

**Validation Rules**:

- `run_metadata` always required
- `metrics.combined` always required
- `signals` populated in dry-run mode
- `executions` populated in full execution mode
- `conflicts` populated only in BOTH mode

**Usage**:

```python
from pydantic import BaseModel

class BacktestResult(BaseModel):
    run_metadata: BacktestRun
    metrics: DirectionalMetrics
    signals: list[TradeSignal] = []
    executions: list[TradeExecution] = []
    conflicts: list[ConflictEvent] = []
```

---

## Data Flows

### Flow 1: LONG-Only Backtest

```text
1. User Input
   └─> CLI args: --direction LONG --data path/to/data.csv

2. Data Loading
   └─> Read CSV → List[Candle]

3. Signal Generation
   └─> generate_long_signals(candles) → List[TradeSignal]

4. Execution Simulation
   └─> For each signal: simulate_execution(signal, candles) → TradeExecution

5. Metrics Aggregation
   └─> Aggregate executions → DirectionalMetrics(long_only=metrics, combined=metrics)

6. Output Formatting
   └─> Format as TEXT or JSON → Write to file

7. User Output
   └─> Display summary, save to backtest_long_YYYYMMDD_HHMMSS.{ext}
```

**Key Transformations**:

- CSV rows → Candle objects (via ingestion.py)
- Candles → TradeSignals (via generate_long_signals)
- TradeSignals → TradeExecutions (via simulate_execution)
- TradeExecutions → MetricsSummary (via metrics aggregation)

---

### Flow 2: SHORT-Only Backtest

```text
1. User Input
   └─> CLI args: --direction SHORT --data path/to/data.csv

2. Data Loading
   └─> Read CSV → List[Candle]

3. Signal Generation
   └─> generate_short_signals(candles) → List[TradeSignal]

4. Execution Simulation
   └─> For each signal: simulate_execution(signal, candles) → TradeExecution

5. Metrics Aggregation
   └─> Aggregate executions → DirectionalMetrics(short_only=metrics, combined=metrics)

6. Output Formatting
   └─> Format as TEXT or JSON → Write to file

7. User Output
   └─> Display summary, save to backtest_short_YYYYMMDD_HHMMSS.{ext}
```

**Key Transformations**: Same as LONG flow, but using generate_short_signals

---

### Flow 3: BOTH Directions Backtest

```text
1. User Input
   └─> CLI args: --direction BOTH --data path/to/data.csv

2. Data Loading
   └─> Read CSV → List[Candle]

3. Signal Generation (Parallel)
   ├─> generate_long_signals(candles) → List[TradeSignal]
   └─> generate_short_signals(candles) → List[TradeSignal]

4. Signal Merging with Conflict Resolution
   └─> merge_signals(long_signals, short_signals)
       ├─> Detect conflicts (same timestamp + pair)
       ├─> Reject conflicting signals → ConflictEvent
       └─> Return merged signal list + conflict events

5. Execution Simulation
   └─> For each merged signal: simulate_execution(signal, candles) → TradeExecution

6. Metrics Aggregation (Three-Tier)
   ├─> Filter executions where direction=="LONG" → long_only_metrics
   ├─> Filter executions where direction=="SHORT" → short_only_metrics
   └─> Aggregate all executions → combined_metrics

7. Output Formatting
   └─> Format as TEXT or JSON → Write to file
       (Include conflict events in output)

8. User Output
   └─> Display summary with directional breakdown, save to backtest_both_YYYYMMDD_HHMMSS.{ext}
```

**Key Transformations**:

- Dual signal lists → Merged signal list (via conflict resolution)
- Merged signals → TradeExecutions (via simulate_execution)
- TradeExecutions → DirectionalMetrics (via three-tier aggregation)

---

### Flow 4: Dry-Run Mode

```text
1. User Input
   └─> CLI args: --direction {LONG|SHORT|BOTH} --data path --dry-run

2. Data Loading
   └─> Read CSV → List[Candle]

3. Signal Generation
   └─> generate_{long|short|both}_signals(candles) → List[TradeSignal]

4. Signal Filtering (Essential Fields Only)
   └─> Extract: timestamp, pair, direction, entry_price, stop_price

5. Output Formatting
   └─> Format signal list as TEXT or JSON → Write to file

6. User Output
   └─> Display signal count and samples, save to backtest_{direction}_YYYYMMDD_HHMMSS.{ext}
```

**Key Transformations**:

- CSV rows → Candle objects
- Candles → TradeSignals (full objects)
- TradeSignals → Essential field subset (for output)
- **Skipped**: Execution simulation, metrics aggregation

---

## Data Validation Rules

### Input Validation

1. **Data File**:
   - Must exist at specified path (FR-017)
   - Must be valid CSV format
   - Must contain required columns: timestamp, open, high, low, close, volume

2. **CLI Arguments**:
   - `--direction` must be in {LONG, SHORT, BOTH}
   - `--output-format` must be in {text, json}
   - `--log-level` must be in {DEBUG, INFO, WARNING, ERROR}

### Processing Validation

1. **Signal Generation**:
   - All signals must have valid timestamps within candle range
   - Entry/stop prices must satisfy direction constraints

2. **Conflict Resolution** (BOTH mode):
   - Conflicts detected by: `signal1.timestamp_utc == signal2.timestamp_utc AND signal1.pair == signal2.pair`
   - Resolution: Reject both signals, log ConflictEvent

3. **Metrics Aggregation**:
   - Handle empty execution lists (trade_count == 0)
   - Set NaN for derived metrics when insufficient data
   - Ensure trade_count == win_count + loss_count

### Output Validation

1. **File Naming**:
   - Format: `backtest_{direction}_{YYYYMMDD}_{HHMMSS}.{ext}`
   - Direction: lowercase (long/short/both)
   - Extension: txt or json

2. **JSON Schema Compliance**:
   - All datetime fields in ISO 8601 UTC format
   - NaN/Infinity serialized as null or string
   - No missing required fields

---

## State Transitions

### Backtest Execution States

```text
INIT → LOADING_DATA → GENERATING_SIGNALS → [RESOLVING_CONFLICTS*] → SIMULATING_EXECUTION** → AGGREGATING_METRICS → FORMATTING_OUTPUT → COMPLETE

* Only in BOTH mode
** Skipped in dry-run mode
```

**State Descriptions**:

- **INIT**: Parse CLI arguments, validate inputs
- **LOADING_DATA**: Read and parse CSV data file
- **GENERATING_SIGNALS**: Call signal generation functions
- **RESOLVING_CONFLICTS**: Merge signals, detect conflicts (BOTH mode)
- **SIMULATING_EXECUTION**: Execute each signal through candles
- **AGGREGATING_METRICS**: Calculate performance metrics
- **FORMATTING_OUTPUT**: Serialize results to text/JSON
- **COMPLETE**: Write output file, display summary

**Error States**:

- **ERROR_FILE_NOT_FOUND**: Data file doesn't exist → exit code 1
- **ERROR_INVALID_ARGS**: Invalid CLI arguments → display help, exit code 1
- **ERROR_DATA_PARSING**: CSV parsing fails → exit code 1

---

## Relationships

```text
BacktestResult
├── run_metadata: BacktestRun
├── metrics: DirectionalMetrics
│   ├── long_only: MetricsSummary (optional)
│   ├── short_only: MetricsSummary (optional)
│   └── combined: MetricsSummary (required)
├── signals: List[TradeSignal] (optional)
├── executions: List[TradeExecution] (optional)
└── conflicts: List[ConflictEvent] (BOTH mode only)

TradeExecution
└── signal_id → TradeSignal.id (reference)

ConflictEvent
└── timestamp_utc, pair (identifies conflicting signal pair)
```

---

## Performance Considerations

### Data Volume Estimates

| Dataset Size | Signal Count (est.) | Execution Time Target | Memory Usage (est.) |
|--------------|---------------------|----------------------|---------------------|
| 10K candles  | 10-50 signals       | <5 seconds           | <50 MB              |
| 100K candles | 100-500 signals     | ≤30 seconds          | <200 MB             |
| 1M candles   | 1K-5K signals       | ~5 minutes           | <1 GB               |

### Optimization Strategies

1. **Generator Patterns**: Use generators for candle iteration to reduce memory
2. **Lazy Evaluation**: Generate signals on-demand rather than all upfront
3. **Batch Processing**: Process signals in batches for metrics aggregation
4. **Minimal Copying**: Pass references rather than copying large datasets

---

## Summary

This data model specification defines all entities, flows, and validation rules for the directional backtesting system. All new entities build upon existing models with minimal additions. The three-tier metrics structure enables comprehensive performance analysis while maintaining simplicity and testability.
