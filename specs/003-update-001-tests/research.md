# Research: Update 001 Test Suite Alignment

## Decisions & Rationale

### Performance Tiering

- **Decision**: Three tiers (unit <5s, integration <30s, performance <120s).
- **Rationale**: Provides clear separation for execution time management and CI pipeline optimization.
- **Alternatives Considered**: Single threshold (rejected: lacks granularity), two tiers (rejected: integration tests may mask longer performance outliers), no tiers (rejected: scalability and clarity issues).

### Deterministic Fixtures

- **Decision**: Use small synthetic OHLC CSV fixtures placed under `tests/fixtures/` with explicit naming (e.g., `fixture_flat_prices.csv`, `fixture_trend_example.csv`).
- **Rationale**: Enables reproducible indicator and signal results while minimizing test runtime.
- **Alternatives**: Large historical dataset slices (rejected: slower, more brittle), autogenerated random data (rejected: increases flakiness unless seeded everywhere).

### Risk Test Coverage

- **Decision**: Retain risk sizing tests validating minimal account, high volatility, and outlier candle scenarios.
- **Rationale**: Preserves core risk management validation aligned with Constitution Principle II.
- **Alternatives**: Reduce scope to only nominal case (rejected: risk regression risk). Add extensive portfolio correlation tests (rejected: out of feature scope).

### Redundant Test Removal Criteria

- **Decision**: Remove tests with identical assertions or those referencing removed interfaces; consolidate overlapping logic into parameterized tests where appropriate.
- **Rationale**: Reduces maintenance surface and CI runtime while maintaining coverage.
- **Alternatives**: Keep all legacy tests (rejected: noise), delete broadly without consolidation (rejected: potential coverage loss).

### Pytest Marker Strategy

- **Decision**: Introduce markers: `@pytest.mark.unit`, `@pytest.mark.integration`, `@pytest.mark.performance`, with marker registration in `pytest.ini`.
- **Rationale**: Enables selective runs locally and in CI; cross-directory classification supported.
- **Alternatives**: Directory-based only (rejected: less flexible), custom runner script (rejected: unnecessary complexity).

### Flakiness Detection Approach

- **Decision**: Run affected tests 3 times locally (scripted loop) when modifying logic to confirm stability before commit; performance tier may be run once due to cost. A test is classified as flaky if it fails ≥1 time in 3 consecutive runs under identical inputs or exhibits runtime variance >±20% of its tier budget without code changes.
- **Rationale**: Quick manual loop is lightweight; avoids introducing dependency on external flakiness tools while providing objective classification threshold.
- **Alternatives**: CI rerun integration (rejected: slower feedback), statistical timing harness (rejected: overkill).

### Naming Conventions

- **Decision**: Use descriptive test function names: `test_indicator_ema_warmup_behavior`, `test_signal_entry_trend_pullback`, etc. Suffix parameterized sets with `_case`. Keep under 88 chars.
- **Rationale**: Improves readability and failure diagnostics.
- **Alternatives**: Abbreviated names (rejected: less clarity).

### Documentation of Removed Tests

- **Decision**: Record removed test file names in commit body under a bullet list with brief reason (e.g., "Removed test_old_signal_flow.py: references deprecated strategy method").
- **Rationale**: Traceability in version history.
- **Alternatives**: Omit reasons (rejected: future confusion), separate markdown log (rejected: duplication).

### Determinism Enforcement

- **Decision**: Explicit seeding (e.g., `random.seed(42)`/numpy seed) in any test introducing randomness; avoid randomness where feasible.
- **Rationale**: Ensures repeatable outcomes.
- **Alternatives**: No seeding (rejected: flakiness risk).

### Threshold Interpretation Clarification

- **Decision**: Tier time budgets (<5s unit, <30s integration, <120s performance) apply to cumulative marker run time, not individual test functions.
- **Tolerance**: ±20% permitted for transient CI variance (e.g., network jitter, VM warm-up) but persistent breaches trigger investigation.
- **Measurement**: Wall-clock measurement via `time.perf_counter()` around full `pytest -m <tier>` invocation.

### Glossary Reference

Formal definitions for deterministic, redundant, flaky, warm-up, fixture manifest, tier runtime maintained in `glossary.md` (eliminates ambiguity in FR-003, FR-004, FR-009, FR-011).

## Open Items Resolved

No remaining NEEDS CLARIFICATION markers after clarify phase.

## Impact Summary

Test runtime predictability, reduced maintenance burden, and enhanced risk validation confidence. Ready for Phase 1 design artifacts.
